{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fdd06fc-5538-4ad1-9ea1-4e351f92ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/fn8dpdw52t58m350b79vc4s00000gn/T/ipykernel_72922/1881398744.py:20: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from datetime import timedelta, datetime\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from sklearn.preprocessing import normalize\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Text, Boolean, LargeBinary, ForeignKey\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "import sqlite3\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# Database setup\n",
    "Base = declarative_base()\n",
    "\n",
    "class AdDetectionResult(Base):\n",
    "    __tablename__ = 'ad_detection_results'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    brand = Column(String(100), nullable=False)\n",
    "    description = Column(Text, nullable=False)\n",
    "    start_time_seconds = Column(Float, nullable=False)\n",
    "    end_time_seconds = Column(Float, nullable=False)\n",
    "    duration_seconds = Column(Float, nullable=False)\n",
    "    correlation_score = Column(Float, nullable=True)\n",
    "    raw_correlation = Column(Float, nullable=True)\n",
    "    mfcc_correlation = Column(Float, nullable=True)\n",
    "    overlap_duration = Column(Float, nullable=True)\n",
    "    detection_timestamp = Column(DateTime, default=datetime.now)\n",
    "    processing_status = Column(String(50), default='completed')\n",
    "    total_matches_found = Column(Integer, default=0)\n",
    "    ad_id = Column(Integer, ForeignKey('ads.id'), nullable=False, default=-1)\n",
    "    broadcast_id = Column(Integer, ForeignKey('broadcasts.id'), nullable=False, default=-1)\n",
    "    \n",
    "    # Relationships\n",
    "    ad = relationship(\"Ads\", back_populates=\"detection_results\")\n",
    "    broadcast = relationship(\"Broadcasts\", back_populates=\"detection_results\")\n",
    "   \n",
    "class ExcelReports(Base):\n",
    "    __tablename__ = 'excel_reports'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    broadcast_id = Column(Integer, ForeignKey('broadcasts.id'), nullable=False)  # ADD THIS LINE\n",
    "    excel_data = Column(LargeBinary, nullable=False)\n",
    "    excel_filename = Column(String(255), nullable=False)\n",
    "    created_timestamp = Column(DateTime, default=datetime.now)\n",
    "    total_ads_detected = Column(Integer, default=0)\n",
    "    file_size_bytes = Column(Integer, default=0)\n",
    "    \n",
    "    # Add relationship\n",
    "    broadcast = relationship(\"Broadcasts\", back_populates=\"excel_reports\")\n",
    "class Ads(Base):\n",
    "    __tablename__ = 'ads'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    brand = Column(String(255), nullable=False)\n",
    "    advertisement = Column(String(255), nullable=False)  # File path or name\n",
    "    duration = Column(Integer, nullable=True)  # Duration in seconds\n",
    "    upload_date = Column(DateTime, default=datetime.now)\n",
    "    status = Column(String(8), default='active')\n",
    "    \n",
    "    # Relationship\n",
    "    detection_results = relationship(\"AdDetectionResult\", back_populates=\"ad\")\n",
    "\n",
    "class Broadcasts(Base):\n",
    "    __tablename__ = 'broadcasts'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    radio_station = Column(String(255), nullable=True)\n",
    "    broadcast_recording = Column(String(255), nullable=False)  # File path or name\n",
    "    duration = Column(Integer, nullable=True)  # Duration in seconds\n",
    "    broadcast_date = Column(DateTime, default=datetime.now)\n",
    "    status = Column(String(9), default='Pending')\n",
    "    \n",
    "    # Relationships\n",
    "    detection_results = relationship(\"AdDetectionResult\", back_populates=\"broadcast\")\n",
    "    excel_reports = relationship(\"ExcelReports\", back_populates=\"broadcast\")  # ADDED\n",
    "\n",
    "# Your existing utility functions (keeping them as they are)\n",
    "def seconds_to_standard_time(seconds):\n",
    "    return str(timedelta(seconds=seconds)).split('.')[0]\n",
    "\n",
    "def extract_brand_name(filename):\n",
    "    \"\"\"Extract brand name from filename - everything before the first underscore\"\"\"\n",
    "    if '_' in filename:\n",
    "        return filename.split('_')[0]\n",
    "    else:\n",
    "        return os.path.splitext(filename)[0]\n",
    "\n",
    "def load_audio(file_path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=22050, mono=True)\n",
    "        return audio, sr\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path} with librosa: {e}\")\n",
    "        try:\n",
    "            sr, audio = wavfile.read(file_path)\n",
    "            if len(audio.shape) > 1:\n",
    "                audio = np.mean(audio, axis=1)\n",
    "            if audio.dtype != np.float32 and audio.dtype != np.float64:\n",
    "                audio = audio.astype(np.float32) / np.iinfo(audio.dtype).max\n",
    "            if sr != 22050:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=22050)\n",
    "                sr = 22050\n",
    "            return audio, sr\n",
    "        except Exception as e2:\n",
    "            print(f\"Error loading {file_path} with scipy: {e2}\")\n",
    "            return None, None\n",
    "\n",
    "def preprocess_audio(audio, sr):\n",
    "    \"\"\"Preprocess audio for better matching\"\"\"\n",
    "    audio = audio / (np.max(np.abs(audio)) + 1e-8)\n",
    "    \n",
    "    pre_emphasis = 0.97\n",
    "    audio = np.append(audio[0], audio[1:] - pre_emphasis * audio[:-1])\n",
    "    \n",
    "    nyquist = sr / 2\n",
    "    low = 300 / nyquist\n",
    "    high = 3400 / nyquist\n",
    "    \n",
    "    if low < 1.0 and high < 1.0:\n",
    "        b, a = signal.butter(4, [low, high], btype='band')\n",
    "        audio = signal.filtfilt(b, a, audio)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def extract_mfcc_features(audio, sr, n_mfcc=13):\n",
    "    \"\"\"Extract MFCC features for better audio matching\"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, n_fft=2048, hop_length=512)\n",
    "    mfcc_delta = librosa.feature.delta(mfccs)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    features = np.vstack([mfccs, mfcc_delta, mfcc_delta2])\n",
    "    return features\n",
    "\n",
    "def compute_feature_correlation(master_features, recording_features):\n",
    "    \"\"\"Compute correlation between feature vectors\"\"\"\n",
    "    master_norm = normalize(master_features, axis=0)\n",
    "    recording_norm = normalize(recording_features, axis=0)\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(master_norm.shape[0]):\n",
    "        corr = signal.correlate(recording_norm[i], master_norm[i], mode='full')\n",
    "        correlations.append(corr)\n",
    "    \n",
    "    avg_correlation = np.mean(correlations, axis=0)\n",
    "    return avg_correlation\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import correlate\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    return (signal - np.mean(signal)) / (np.std(signal) + 1e-10)\n",
    "\n",
    "def find_matches_improved(master_audio, master_sr, radio_audio, radio_sr, threshold=0.65):\n",
    "    \"\"\"\n",
    "    Improved ad detection using normalized cross-correlation.\n",
    "    Works with .mp3 or .wav master files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Resample ad audio to match radio sampling rate\n",
    "    if master_sr != radio_sr:\n",
    "        master_audio = librosa.resample(master_audio, orig_sr=master_sr, target_sr=radio_sr)\n",
    "        master_sr = radio_sr\n",
    "\n",
    "    # Step 2: Normalize both signals\n",
    "    master_audio = normalize_signal(master_audio)\n",
    "    radio_audio = normalize_signal(radio_audio)\n",
    "\n",
    "    # Step 3: Cross-correlation\n",
    "    correlation = correlate(radio_audio, master_audio, mode='valid')\n",
    "    correlation /= len(master_audio)\n",
    "\n",
    "    matches = []\n",
    "    ad_duration = len(master_audio) / radio_sr\n",
    "\n",
    "    i = 0\n",
    "    while i < len(correlation):\n",
    "        if correlation[i] >= threshold:\n",
    "            start_time = i / radio_sr\n",
    "            end_time = start_time + ad_duration\n",
    "            matches.append({\n",
    "                'start_time': start_time,\n",
    "                'end_time': end_time,\n",
    "                'duration': ad_duration,\n",
    "                'correlation': float(round(correlation[i], 4))\n",
    "            })\n",
    "            # Skip forward by ad duration to avoid overlap\n",
    "            i += int(ad_duration * radio_sr)\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return matches\n",
    "\n",
    "# Enhanced Database Manager Class\n",
    "class EnhancedRadioRecordingManager:\n",
    "    def __init__(self, db_path=\"radio_ad_detection.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.engine = create_engine(f'sqlite:///{db_path}')\n",
    "        Base.metadata.create_all(self.engine)\n",
    "        Session = sessionmaker(bind=self.engine)\n",
    "        self.Session = Session\n",
    "    \n",
    "    def get_ad_id_by_filename(self, filename):\n",
    "        \"\"\"Get ad ID from the ads table by filename\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            ad = session.query(Ads).filter(Ads.advertisement == filename).first()\n",
    "            return ad.id if ad else -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting ad ID for {filename}: {e}\")\n",
    "            return -1\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_broadcast_id_by_filename(self, filename):\n",
    "        \"\"\"Get broadcast ID from the broadcasts table by filename\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            broadcast = session.query(Broadcasts).filter(Broadcasts.broadcast_recording == filename).first()\n",
    "            return broadcast.id if broadcast else -1\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting broadcast ID for {filename}: {e}\")\n",
    "            return -1\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    # NEW METHODS FOR ADS TABLE\n",
    "    def populate_ads_from_folder(self, ad_masters_folder=\"ad_masters\"):\n",
    "        \"\"\"Populate ads table from ad_masters folder\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            print(f\" Scanning {ad_masters_folder} for advertisement files...\")\n",
    "            \n",
    "            if not os.path.exists(ad_masters_folder):\n",
    "                print(f\"✗ Folder {ad_masters_folder} does not exist\")\n",
    "                return 0\n",
    "            \n",
    "            added_count = 0\n",
    "            updated_count = 0\n",
    "            \n",
    "            for filename in os.listdir(ad_masters_folder):\n",
    "                if filename.endswith(('.wav', '.mp3')):\n",
    "                    filepath = os.path.join(ad_masters_folder, filename)\n",
    "                    \n",
    "                    # Check if ad already exists\n",
    "                    existing_ad = session.query(Ads).filter(\n",
    "                        Ads.advertisement == filename\n",
    "                    ).first()\n",
    "                    \n",
    "                    # Get duration\n",
    "                    duration_seconds = None\n",
    "                    try:\n",
    "                        audio, sr = load_audio(filepath)\n",
    "                        if audio is not None:\n",
    "                            duration_seconds = int(len(audio) / sr)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    brand_name = extract_brand_name(filename)\n",
    "                    \n",
    "                    if existing_ad:\n",
    "                        # Update existing record\n",
    "                        existing_ad.brand = brand_name\n",
    "                        existing_ad.duration = duration_seconds\n",
    "                        existing_ad.status = 'active'\n",
    "                        updated_count += 1\n",
    "                    else:\n",
    "                        # Add new record\n",
    "                        new_ad = Ads(\n",
    "                            brand=brand_name,\n",
    "                            advertisement=filename,\n",
    "                            duration=duration_seconds,\n",
    "                            status='active'\n",
    "                        )\n",
    "                        session.add(new_ad)\n",
    "                        added_count += 1\n",
    "            \n",
    "            session.commit()\n",
    "            print(f\" Ads table updated:\")\n",
    "            print(f\"  - New ads added: {added_count}\")\n",
    "            print(f\"  - Existing ads updated: {updated_count}\")\n",
    "            \n",
    "            return added_count + updated_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\"✗ Error populating ads table: {e}\")\n",
    "            return 0\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_all_ads(self):\n",
    "        \"\"\"Get all ads from the database\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            ads = session.query(Ads).order_by(Ads.brand, Ads.advertisement).all()\n",
    "            \n",
    "            if not ads:\n",
    "                print(\"No ads found in database.\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"\\n Advertisement Masters ({len(ads)}):\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            ads_info = []\n",
    "            for i, ad in enumerate(ads, 1):\n",
    "                duration_str = seconds_to_standard_time(ad.duration) if ad.duration else \"Unknown\"\n",
    "                info = {\n",
    "                    'id': ad.id,\n",
    "                    'brand': ad.brand,\n",
    "                    'advertisement': ad.advertisement,\n",
    "                    'duration': ad.duration,\n",
    "                    'duration_str': duration_str,\n",
    "                    'upload_date': ad.upload_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'status': ad.status\n",
    "                }\n",
    "                ads_info.append(info)\n",
    "                \n",
    "                print(f\"{i:2d}. {ad.brand} - {ad.advertisement} (ID: {ad.id})\")\n",
    "                print(f\"     Duration: {duration_str} | Status: {ad.status} | Uploaded: {info['upload_date']}\")\n",
    "                print()\n",
    "            \n",
    "            return ads_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting ads: {e}\")\n",
    "            return []\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    # NEW METHODS FOR BROADCASTS TABLE\n",
    "    def add_broadcast(self, broadcast_recording, radio_station=None, duration=None, broadcast_date=None, status='Pending'):\n",
    "        \"\"\"Add a new broadcast to the database\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            # Check if broadcast already exists\n",
    "            existing = session.query(Broadcasts).filter(\n",
    "                Broadcasts.broadcast_recording == broadcast_recording\n",
    "            ).first()\n",
    "            \n",
    "            if existing:\n",
    "                print(f\" Broadcast {broadcast_recording} already exists in database (ID: {existing.id})\")\n",
    "                return existing.id\n",
    "            \n",
    "            if broadcast_date is None:\n",
    "                broadcast_date = datetime.now()\n",
    "            \n",
    "            new_broadcast = Broadcasts(\n",
    "                radio_station=radio_station,\n",
    "                broadcast_recording=broadcast_recording,\n",
    "                duration=duration,\n",
    "                broadcast_date=broadcast_date,\n",
    "                status=status\n",
    "            )\n",
    "            \n",
    "            session.add(new_broadcast)\n",
    "            session.commit()\n",
    "            \n",
    "            print(f\" Added broadcast: {broadcast_recording} (ID: {new_broadcast.id})\")\n",
    "            return new_broadcast.id\n",
    "            \n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\" Error adding broadcast: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def update_broadcast_status(self, broadcast_recording, status):\n",
    "        \"\"\"Update broadcast processing status\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            broadcast = session.query(Broadcasts).filter(\n",
    "                Broadcasts.broadcast_recording == broadcast_recording\n",
    "            ).first()\n",
    "            \n",
    "            if broadcast:\n",
    "                broadcast.status = status\n",
    "                session.commit()\n",
    "                print(f\" Updated {broadcast_recording} status to: {status}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\" Broadcast {broadcast_recording} not found\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\" Error updating broadcast status: {e}\")\n",
    "            return False\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_all_broadcasts(self):\n",
    "        \"\"\"Get all broadcasts from the database\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            broadcasts = session.query(Broadcasts).order_by(Broadcasts.broadcast_date.desc()).all()\n",
    "            \n",
    "            if not broadcasts:\n",
    "                print(\"No broadcasts found in database.\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"\\n Broadcast Recordings ({len(broadcasts)}):\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            broadcasts_info = []\n",
    "            for i, broadcast in enumerate(broadcasts, 1):\n",
    "                duration_str = seconds_to_standard_time(broadcast.duration) if broadcast.duration else \"Unknown\"\n",
    "                info = {\n",
    "                    'id': broadcast.id,\n",
    "                    'radio_station': broadcast.radio_station or \"Unknown\",\n",
    "                    'broadcast_recording': broadcast.broadcast_recording,\n",
    "                    'duration': broadcast.duration,\n",
    "                    'duration_str': duration_str,\n",
    "                    'broadcast_date': broadcast.broadcast_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'status': broadcast.status\n",
    "                }\n",
    "                broadcasts_info.append(info)\n",
    "                \n",
    "                print(f\"{i:2d}. {broadcast.broadcast_recording} (ID: {broadcast.id})\")\n",
    "                print(f\"     Station: {info['radio_station']} | Duration: {duration_str}\")\n",
    "                print(f\"     Date: {info['broadcast_date']} | Status: {broadcast.status}\")\n",
    "                print()\n",
    "            \n",
    "            return broadcasts_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting broadcasts: {e}\")\n",
    "            return []\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def save_detection_results(self, matches_dict, radio_filename):\n",
    "        \"\"\"Save detection results to database for a specific radio recording\"\"\"\n",
    "        session = self.Session()\n",
    "        \n",
    "        try:\n",
    "            # Get broadcast ID for this radio file\n",
    "            broadcast_id = self.get_broadcast_id_by_filename(radio_filename)\n",
    "            \n",
    "            if broadcast_id == -1:\n",
    "                print(f\"⚠ Warning: Broadcast {radio_filename} not found in database\")\n",
    "                return 0\n",
    "            \n",
    "            # Clear existing results for this broadcast (for reprocessing)\n",
    "            session.query(AdDetectionResult).filter(\n",
    "                AdDetectionResult.broadcast_id == broadcast_id\n",
    "            ).delete()\n",
    "            \n",
    "            # Process and filter matches\n",
    "            all_matches = []\n",
    "            for master_name, matches in matches_dict.items():\n",
    "                # Get ad ID for this master file\n",
    "                ad_id = self.get_ad_id_by_filename(master_name)\n",
    "                \n",
    "                for match in matches:\n",
    "                    all_matches.append({\n",
    "                        'master_name': master_name,\n",
    "                        'ad_id': ad_id,\n",
    "                        'start_time': match['start_time'],\n",
    "                        'end_time': match['end_time'],\n",
    "                        'duration': match['duration'],\n",
    "                        'correlation': match['correlation'],\n",
    "                        'overlap_duration': match.get('overlap_duration', match['duration']),\n",
    "                        'raw_correlation': match.get('raw_correlation', match['correlation']),\n",
    "                        'mfcc_correlation': match.get('mfcc_correlation', match['correlation'])\n",
    "                    })\n",
    "            \n",
    "            # Sort and filter overlapping matches\n",
    "            all_matches.sort(key=lambda x: x['start_time'])\n",
    "            final_matches = self._filter_overlapping_matches(all_matches)\n",
    "            \n",
    "            # Save to database\n",
    "            for match in final_matches:\n",
    "                brand_name = extract_brand_name(match['master_name'])\n",
    "                description = os.path.splitext(match['master_name'])[0]\n",
    "                \n",
    "                db_record = AdDetectionResult(\n",
    "                    brand=brand_name,\n",
    "                    description=description,\n",
    "                    start_time_seconds=match['start_time'],\n",
    "                    end_time_seconds=match['end_time'],\n",
    "                    duration_seconds=match['duration'],\n",
    "                    correlation_score=match['correlation'],\n",
    "                    raw_correlation=match['raw_correlation'],\n",
    "                    mfcc_correlation=match['mfcc_correlation'],\n",
    "                    overlap_duration=match['overlap_duration'],\n",
    "                    total_matches_found=len(final_matches),\n",
    "                    ad_id=match['ad_id'],\n",
    "                    broadcast_id=broadcast_id\n",
    "                )\n",
    "                session.add(db_record)\n",
    "            \n",
    "            session.commit()\n",
    "            print(f\" Saved {len(final_matches)} detection results for {radio_filename}\")\n",
    "            print(f\"   - Broadcast ID: {broadcast_id}\")\n",
    "            print(f\"   - Ad IDs linked successfully\")\n",
    "            \n",
    "            # Update broadcast status to \"Completed\" if it exists\n",
    "            self.update_broadcast_status(radio_filename, \"Completed\")\n",
    "            \n",
    "            # Generate and store Excel report\n",
    "            self._generate_and_store_excel(broadcast_id, final_matches)\n",
    "            \n",
    "            return len(final_matches)\n",
    "            \n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\" Error saving results: {e}\")\n",
    "            return 0\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def _filter_overlapping_matches(self, all_matches):\n",
    "        \"\"\"Apply filtering logic for overlapping matches\"\"\"\n",
    "        final_matches = []\n",
    "        for match in all_matches:\n",
    "            should_keep = True\n",
    "            \n",
    "            for i, existing_match in enumerate(final_matches):\n",
    "                overlap_start = max(match['start_time'], existing_match['start_time'])\n",
    "                overlap_end = min(match['end_time'], existing_match['end_time'])\n",
    "                overlap_duration = max(0, overlap_end - overlap_start)\n",
    "                \n",
    "                min_duration = min(match['duration'], existing_match['duration'])\n",
    "                \n",
    "                if overlap_duration > (0.4 * min_duration):\n",
    "                    current_score = match['correlation']\n",
    "                    existing_score = existing_match['correlation']\n",
    "                    \n",
    "                    if current_score > existing_score:\n",
    "                        final_matches[i] = match\n",
    "                        should_keep = False\n",
    "                        break\n",
    "                    else:\n",
    "                        should_keep = False\n",
    "                        break\n",
    "            \n",
    "            if should_keep:\n",
    "                final_matches.append(match)\n",
    "        \n",
    "        return final_matches\n",
    "    \n",
    "    def _generate_and_store_excel(self, broadcast_id, final_matches):\n",
    "        \"\"\"Generate Excel and store in database - WITHOUT correlation score\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            # Get broadcast info\n",
    "            broadcast = session.query(Broadcasts).filter(Broadcasts.id == broadcast_id).first()\n",
    "            if not broadcast:\n",
    "                print(f\" Broadcast with ID {broadcast_id} not found\")\n",
    "                return\n",
    "            \n",
    "            # Create Excel in memory\n",
    "            output = BytesIO()\n",
    "            \n",
    "            # Prepare data - REMOVED correlation score column\n",
    "            data = []\n",
    "            header_data = {\n",
    "                'Brand': 'Brand',\n",
    "                'Description': 'Description',\n",
    "                'Start Time (HH:MM:SS)': 'Start Time (HH:MM:SS)',\n",
    "                'End Time (HH:MM:SS)': 'End Time (HH:MM:SS)',\n",
    "                'Ad Duration (HH:MM:SS)': 'Ad Duration (HH:MM:SS)'\n",
    "            }\n",
    "            data.append(header_data)\n",
    "            \n",
    "            for match in final_matches:\n",
    "                start_rounded = max(0, round(match['start_time']))\n",
    "                end_rounded = round(match['end_time'])\n",
    "                duration_rounded = end_rounded - start_rounded\n",
    "                \n",
    "                data.append({\n",
    "                    'Brand': extract_brand_name(match['master_name']),\n",
    "                    'Description': os.path.splitext(match['master_name'])[0],\n",
    "                    'Start Time (HH:MM:SS)': seconds_to_standard_time(start_rounded),\n",
    "                    'End Time (HH:MM:SS)': seconds_to_standard_time(end_rounded),\n",
    "                    'Ad Duration (HH:MM:SS)': seconds_to_standard_time(abs(duration_rounded))\n",
    "                })\n",
    "            \n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
    "                df.to_excel(writer, sheet_name='Ad Detection Results', index=False, header=False)\n",
    "                \n",
    "                workbook = writer.book\n",
    "                worksheet = writer.sheets['Ad Detection Results']\n",
    "                \n",
    "                from openpyxl.styles import PatternFill, Font, Alignment\n",
    "                \n",
    "                yellow_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")\n",
    "                bold_font = Font(bold=True)\n",
    "                center_alignment = Alignment(horizontal=\"center\")\n",
    "                \n",
    "                # Format header row\n",
    "                for col in range(1, len(df.columns) + 1):\n",
    "                    cell = worksheet.cell(row=1, column=col)\n",
    "                    cell.fill = yellow_fill\n",
    "                    cell.font = bold_font\n",
    "                    cell.alignment = center_alignment\n",
    "                \n",
    "                # Adjust column widths - REMOVED correlation score column width\n",
    "                worksheet.column_dimensions['A'].width = 20\n",
    "                worksheet.column_dimensions['B'].width = 60\n",
    "                worksheet.column_dimensions['C'].width = 18\n",
    "                worksheet.column_dimensions['D'].width = 18\n",
    "                worksheet.column_dimensions['E'].width = 20\n",
    "            \n",
    "            excel_data = output.getvalue()\n",
    "            \n",
    "            # Store Excel in database\n",
    "            excel_filename = f\"detection_results_{broadcast.broadcast_recording.replace('.mp3', '').replace('.wav', '')}.xlsx\"\n",
    "            \n",
    "            # Remove existing Excel report for this broadcast\n",
    "            session.query(ExcelReports).filter(\n",
    "                ExcelReports.broadcast_id == broadcast_id\n",
    "            ).delete()\n",
    "            \n",
    "            excel_record = ExcelReports(\n",
    "                broadcast_id=broadcast_id,\n",
    "                excel_data=excel_data,\n",
    "                excel_filename=excel_filename,\n",
    "                total_ads_detected=len(final_matches),\n",
    "                file_size_bytes=len(excel_data)\n",
    "            )\n",
    "            session.add(excel_record)\n",
    "            session.commit()\n",
    "            \n",
    "            print(f\" Excel report stored in database for broadcast ID {broadcast_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            print(f\" Error storing Excel: {e}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_radio_recordings_list(self):\n",
    "        \"\"\"Get list of all processed radio recordings\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            broadcasts = session.query(Broadcasts.broadcast_recording).all()\n",
    "            return [b[0] for b in broadcasts]\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting recordings list: {e}\")\n",
    "            return []\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def download_excel_by_filename(self, radio_filename, save_path=None):\n",
    "        \"\"\"Download Excel file from database by radio filename\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            # Get broadcast ID first\n",
    "            broadcast = session.query(Broadcasts).filter(\n",
    "                Broadcasts.broadcast_recording == radio_filename\n",
    "            ).first()\n",
    "            \n",
    "            if not broadcast:\n",
    "                print(f\"No broadcast found for: {radio_filename}\")\n",
    "                return None\n",
    "            \n",
    "            excel_record = session.query(ExcelReports).filter(\n",
    "                ExcelReports.broadcast_id == broadcast.id\n",
    "            ).first()\n",
    "            \n",
    "            if not excel_record:\n",
    "                print(f\"No Excel report found for: {radio_filename}\")\n",
    "                return None\n",
    "            \n",
    "            if save_path is None:\n",
    "                save_path = excel_record.excel_filename\n",
    "            \n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(excel_record.excel_data)\n",
    "            \n",
    "            print(f\" Excel downloaded: {save_path}\")\n",
    "            print(f\"  - Total ads detected: {excel_record.total_ads_detected}\")\n",
    "            print(f\"  - File size: {excel_record.file_size_bytes} bytes\")\n",
    "            print(f\"  - Created: {excel_record.created_timestamp}\")\n",
    "            \n",
    "            return save_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error downloading Excel: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_all_available_reports(self):\n",
    "        \"\"\"Get information about all available Excel reports\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            reports = session.query(ExcelReports, Broadcasts).join(\n",
    "                Broadcasts, ExcelReports.broadcast_id == Broadcasts.id\n",
    "            ).order_by(ExcelReports.created_timestamp.desc()).all()\n",
    "            \n",
    "            if not reports:\n",
    "                print(\"No reports available in database.\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"\\n Available Reports ({len(reports)}):\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            report_info = []\n",
    "            for i, (report, broadcast) in enumerate(reports, 1):\n",
    "                info = {\n",
    "                    'id': report.id,\n",
    "                    'radio_file': broadcast.broadcast_recording,\n",
    "                    'excel_filename': report.excel_filename,\n",
    "                    'ads_detected': report.total_ads_detected,\n",
    "                    'created': report.created_timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'size_kb': round(report.file_size_bytes / 1024, 2),\n",
    "                    'broadcast_id': broadcast.id\n",
    "                }\n",
    "                report_info.append(info)\n",
    "                \n",
    "                print(f\"{i:2d}. {broadcast.broadcast_recording}\")\n",
    "                print(f\"     Excel: {report.excel_filename}\")\n",
    "                print(f\"     Ads: {report.total_ads_detected} | Created: {info['created']} | Size: {info['size_kb']} KB\")\n",
    "                print()\n",
    "            \n",
    "            return report_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting reports: {e}\")\n",
    "            return []\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_detection_summary(self, radio_filename):\n",
    "        \"\"\"Get detailed summary of detection results\"\"\"\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            # Get broadcast first\n",
    "            broadcast = session.query(Broadcasts).filter(\n",
    "                Broadcasts.broadcast_recording == radio_filename\n",
    "            ).first()\n",
    "            \n",
    "            if not broadcast:\n",
    "                print(f\" No broadcast found for: {radio_filename}\")\n",
    "                return None\n",
    "            \n",
    "            results = session.query(AdDetectionResult).filter(\n",
    "                AdDetectionResult.broadcast_id == broadcast.id\n",
    "            ).order_by(AdDetectionResult.start_time_seconds.asc()).all()\n",
    "            \n",
    "            if not results:\n",
    "                print(f\" No results found for: {radio_filename}\")\n",
    "                return None\n",
    "            \n",
    "            print(f\"\\n Detection Summary for: {radio_filename}\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Total Ads Detected: {len(results)}\")\n",
    "            print(f\"Processing Date: {results[0].detection_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"Broadcast ID: {results[0].broadcast_id}\")\n",
    "            print()\n",
    "            \n",
    "            # Brand summary\n",
    "            brand_counts = {}\n",
    "            total_duration = 0\n",
    "            \n",
    "            for result in results:\n",
    "                brand_counts[result.brand] = brand_counts.get(result.brand, 0) + 1\n",
    "                total_duration += result.duration_seconds\n",
    "            \n",
    "            print(\" Brand Breakdown:\")\n",
    "            for brand, count in sorted(brand_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  {brand}: {count} ads\")\n",
    "            \n",
    "            print(f\"\\n Total Ad Duration: {seconds_to_standard_time(total_duration)}\")\n",
    "            print(f\" Average Correlation Score: {np.mean([r.correlation_score for r in results]):.4f}\")\n",
    "            \n",
    "            # Show first few results with IDs\n",
    "            print(f\"\\n First 5 Detections (with IDs):\")\n",
    "            for i, result in enumerate(results[:5], 1):\n",
    "                print(f\"  {i}. {result.brand} | Ad ID: {result.ad_id} | {seconds_to_standard_time(result.start_time_seconds)}\")\n",
    "            \n",
    "            return {\n",
    "                'total_ads': len(results),\n",
    "                'brands': brand_counts,\n",
    "                'total_duration': total_duration,\n",
    "                'avg_correlation': np.mean([r.correlation_score for r in results]),\n",
    "                'broadcast_id': results[0].broadcast_id\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting summary: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d4e0be9-ed98-4c1f-afc6-98814a72af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enhanced Radio Advertisement Detection System\n",
      "==================================================\n",
      " Setting up database and populating ads table...\n",
      " Setting up database tables...\n",
      " Scanning ad_masters for advertisement files...\n",
      " Ads table updated:\n",
      "  - New ads added: 0\n",
      "  - Existing ads updated: 141\n",
      " Database setup complete!\n",
      "  - Advertisement masters: 141\n",
      "\n",
      " Processing: FMLogger_20211119_063901Z_98300000Hz_AF.mp3\n",
      "==================================================\n",
      " Added broadcast: FMLogger_20211119_063901Z_98300000Hz_AF.mp3 (ID: 7)\n",
      " Loading advertisement masters...\n",
      " Loaded 141 advertisement masters\n",
      " Loading radio recording...\n",
      " Loaded radio recording (Duration: 0:14:56)\n",
      " Finding advertisement matches...\n",
      "   Radio Tune_bhak bhak bhak mirchi bhak bhak 98.3 bhak_98.3 06.12.2021-01.mp3: 2 matches\n",
      "   Ghoomer_Vaa vaa vaa vandhu gumar gumar aat_98.3 06.12.2021.mp3: 1 matches\n",
      "   Radio Tune_yo 98.3 sach mai ye bada crazy_98.3 06.12.2021-01.mp3: 1 matches\n",
      "   Bhabi_Bhabi Meri Umar Neyani munda tu si velly labeya_98.3 06.12.2021.mp3: 1 matches\n",
      "   Tera Ghata_kuch soch ke bola hoga tume ye pyar bhi tola_98.33 06.12.2021.mp3: 1 matches\n",
      "   Radio Tune_bhak bhak bhak mirchi bhak bhak 98.3 bhak_98.3 06.12.2021.mp3: 1 matches\n",
      "   Radio Tune_yo 98.3 sach mai ye bada crazy_98.3 06.12.2021.mp3: 1 matches\n",
      "   Ik Tera_karvauna chal chal naal soniye ni ikk tere kharche oye_ 98.3 06.12.2021.mp3: 1 matches\n",
      "   Chance Pe Dance_left leg piche piche right leg aage aage_98.3 06.12.2021.mp3: 1 matches\n",
      " Total raw matches found: 10\n",
      " Saved 9 detection results for FMLogger_20211119_063901Z_98300000Hz_AF.mp3\n",
      "   - Broadcast ID: 7\n",
      "   - Ad IDs linked successfully\n",
      " Updated FMLogger_20211119_063901Z_98300000Hz_AF.mp3 status to: Completed\n",
      " Excel report stored in database for broadcast ID 7\n",
      " Processing completed successfully!\n",
      "    Final matches: 9\n",
      "    Results saved to database\n",
      "    Excel report generated and stored\n",
      "\n",
      " Detection Summary for: FMLogger_20211119_063901Z_98300000Hz_AF.mp3\n",
      "============================================================\n",
      "Total Ads Detected: 9\n",
      "Processing Date: 2025-06-11 15:57:16\n",
      "Broadcast ID: 7\n",
      "\n",
      " Brand Breakdown:\n",
      "  Radio Tune: 4 ads\n",
      "  Ik Tera: 1 ads\n",
      "  Ghoomer: 1 ads\n",
      "  Tera Ghata: 1 ads\n",
      "  Chance Pe Dance: 1 ads\n",
      "  Bhabi: 1 ads\n",
      "\n",
      " Total Ad Duration: 0:14:53\n",
      " Average Correlation Score: 0.7480\n",
      "\n",
      " First 5 Detections (with IDs):\n",
      "  1. Ik Tera | Ad ID: 119 | 0:00:00\n",
      "  2. Radio Tune | Ad ID: 115 | 0:00:31\n",
      "  3. Ghoomer | Ad ID: 4 | 0:00:44\n",
      "  4. Radio Tune | Ad ID: 2 | 0:03:57\n",
      "  5. Tera Ghata | Ad ID: 77 | 0:04:10\n",
      "\n",
      " Successfully processed: FMLogger_20211119_063901Z_98300000Hz_AF.mp3\n",
      " You can now:\n",
      "   1. View reports: list_all_reports()\n",
      "   2. Download Excel: fetch_excel_report('FMLogger_20211119_063901Z_98300000Hz_AF.mp3')\n",
      "   3. Get summary: get_report_summary('FMLogger_20211119_063901Z_98300000Hz_AF.mp3')\n",
      "\n",
      " Available commands:\n",
      "   list_all_reports()                          # Show all reports\n",
      "   fetch_excel_report('FMLogger_20211119_063901Z_98300000Hz_AF.mp3')       # Download Excel\n",
      "   get_report_summary('FMLogger_20211119_063901Z_98300000Hz_AF.mp3')       # Show summary\n",
      "   download_latest_report()                    # Quick download\n",
      "   view_all_ads()                              # Show all ads\n",
      "   view_all_broadcasts()                       # Show all broadcasts\n",
      "   show_database_overview()                    # Complete overview\n",
      "\n",
      "============================================================\n",
      " READY TO USE - Key Functions:\n",
      "============================================================\n",
      "1.  setup_database_tables()                # First-time setup\n",
      "2.  process_current_audio_clip()           # Process current audio\n",
      "3.  list_all_reports()                     # Show all reports\n",
      "4.  fetch_excel_report('filename.mp3')     # Download specific Excel\n",
      "5.  get_report_summary('filename.mp3')     # Show detection summary\n",
      "6.  download_latest_report()               # Quick download latest\n",
      "7.  view_all_ads()                         # Show advertisement masters\n",
      "8.  view_all_broadcasts()                  # Show broadcast recordings\n",
      "9.  show_database_overview()               # Complete database overview\n",
      "10. update_ads_database()                  # Update ads from folder\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Main processing function for single audio clip\n",
    "def process_single_radio_clip(ad_masters_folder, radio_recording_file_path, \n",
    "                            correlation_threshold=0.65, db_manager=None):\n",
    "    \"\"\"Process a single radio recording clip and save everything to database\"\"\"\n",
    "    \n",
    "    if db_manager is None:\n",
    "        db_manager = EnhancedRadioRecordingManager()\n",
    "    \n",
    "    radio_filename = os.path.basename(radio_recording_file_path)\n",
    "    \n",
    "    print(f\"\\n Processing: {radio_filename}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Add broadcast to database if not exists\n",
    "    try:\n",
    "        audio, sr = load_audio(radio_recording_file_path)\n",
    "        if audio is not None:\n",
    "            duration_seconds = int(len(audio) / sr)\n",
    "        else:\n",
    "            duration_seconds = None\n",
    "    except:\n",
    "        duration_seconds = None\n",
    "    \n",
    "    db_manager.add_broadcast(\n",
    "        broadcast_recording=radio_filename,\n",
    "        duration=duration_seconds,\n",
    "        status='Processing'\n",
    "    )\n",
    "    \n",
    "    # Load advertisement masters\n",
    "    print(\" Loading advertisement masters...\")\n",
    "    masters = {}\n",
    "    for filename in os.listdir(ad_masters_folder):\n",
    "        if filename.endswith(('.wav', '.mp3')):\n",
    "            filepath = os.path.join(ad_masters_folder, filename)\n",
    "            audio, sr = load_audio(filepath)\n",
    "            if audio is not None:\n",
    "                masters[filename] = {\n",
    "                    'audio': audio,\n",
    "                    'sr': sr,\n",
    "                    'duration': len(audio) / sr\n",
    "                }\n",
    "    \n",
    "    print(f\" Loaded {len(masters)} advertisement masters\")\n",
    "    \n",
    "    # Load radio recording\n",
    "    print(\" Loading radio recording...\")\n",
    "    radio_recording, radio_sr = load_audio(radio_recording_file_path)\n",
    "    if radio_recording is None:\n",
    "        print(f\" Error: Could not load radio recording\")\n",
    "        db_manager.update_broadcast_status(radio_filename, \"Failed\")\n",
    "        return False\n",
    "    \n",
    "    radio_duration = len(radio_recording) / radio_sr\n",
    "    print(f\" Loaded radio recording (Duration: {seconds_to_standard_time(radio_duration)})\")\n",
    "    \n",
    "    # Find matches\n",
    "    print(\" Finding advertisement matches...\")\n",
    "    all_matches = {}\n",
    "    total_matches = 0\n",
    "    \n",
    "    for master_name, master_data in masters.items():\n",
    "        matches = find_matches_improved(\n",
    "            master_data['audio'], \n",
    "            master_data['sr'], \n",
    "            radio_recording, \n",
    "            radio_sr, \n",
    "            threshold=correlation_threshold\n",
    "        )\n",
    "        all_matches[master_name] = matches\n",
    "        total_matches += len(matches)\n",
    "        if len(matches) > 0:\n",
    "            print(f\"   {master_name}: {len(matches)} matches\")\n",
    "    \n",
    "    print(f\" Total raw matches found: {total_matches}\")\n",
    "    \n",
    "    # Save to database (this also generates and stores Excel)\n",
    "    final_matches = db_manager.save_detection_results(all_matches, radio_filename)\n",
    "    \n",
    "    if final_matches > 0:\n",
    "        print(f\" Processing completed successfully!\")\n",
    "        print(f\"    Final matches: {final_matches}\")\n",
    "        print(f\"    Results saved to database\")\n",
    "        print(f\"    Excel report generated and stored\")\n",
    "        \n",
    "        # Show summary\n",
    "        db_manager.get_detection_summary(radio_filename)\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(f\"  No matches found above threshold\")\n",
    "        db_manager.update_broadcast_status(radio_filename, \"No Matches\")\n",
    "        return False\n",
    "\n",
    "# NEW CONVENIENCE FUNCTIONS FOR THE NEW TABLES\n",
    "def setup_database_tables(ad_masters_folder=\"ad_masters\"):\n",
    "    \"\"\"Initialize and populate ads table from ad_masters folder\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    \n",
    "    print(\" Setting up database tables...\")\n",
    "    \n",
    "    # Populate ads table\n",
    "    ads_count = db_manager.populate_ads_from_folder(ad_masters_folder)\n",
    "    \n",
    "    print(f\" Database setup complete!\")\n",
    "    print(f\"  - Advertisement masters: {ads_count}\")\n",
    "    \n",
    "    return db_manager\n",
    "\n",
    "def view_all_ads():\n",
    "    \"\"\"View all advertisement masters in database\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.get_all_ads()\n",
    "\n",
    "def view_all_broadcasts():\n",
    "    \"\"\"View all broadcast recordings in database\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.get_all_broadcasts()\n",
    "\n",
    "def add_new_broadcast(broadcast_file, radio_station=None, duration=None):\n",
    "    \"\"\"Add a new broadcast to the database\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.add_broadcast(broadcast_file, radio_station, duration)\n",
    "\n",
    "def update_ads_database(ad_masters_folder=\"ad_masters\"):\n",
    "    \"\"\"Update ads table with any new advertisement files\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.populate_ads_from_folder(ad_masters_folder)\n",
    "\n",
    "# Convenience functions for database access\n",
    "def fetch_excel_report(radio_filename, download_path=None):\n",
    "    \"\"\"Fetch Excel report from database by radio filename\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.download_excel_by_filename(radio_filename, download_path)\n",
    "\n",
    "def list_all_reports():\n",
    "    \"\"\"List all available reports in database\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.get_all_available_reports()\n",
    "\n",
    "def get_report_summary(radio_filename):\n",
    "    \"\"\"Get detailed summary of a specific report\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    return db_manager.get_detection_summary(radio_filename)\n",
    "\n",
    "# Main execution functions\n",
    "def process_current_audio_clip(ad_masters_folder=\"ad_masters\", radio_recording_folder=\"radio_recording\", \n",
    "                              correlation_threshold=0.65):\n",
    "    \"\"\"Process the single audio clip currently in radio_recording folder\"\"\"\n",
    "    \n",
    "    # Get the single audio file in the folder\n",
    "    audio_files = []\n",
    "    for filename in os.listdir(radio_recording_folder):\n",
    "        if filename.endswith(('.wav', '.mp3')):\n",
    "            audio_files.append(filename)\n",
    "    \n",
    "    if len(audio_files) == 0:\n",
    "        print(\" No audio files found in radio_recording folder\")\n",
    "        return False\n",
    "    elif len(audio_files) > 1:\n",
    "        print(f\"  Multiple audio files found. Processing the first one: {audio_files[0]}\")\n",
    "    \n",
    "    audio_file = audio_files[0]\n",
    "    audio_path = os.path.join(radio_recording_folder, audio_file)\n",
    "    \n",
    "    # Process the single clip\n",
    "    success = process_single_radio_clip(ad_masters_folder, audio_path, correlation_threshold)\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\n Successfully processed: {audio_file}\")\n",
    "        print(\" You can now:\")\n",
    "        print(f\"   1. View reports: list_all_reports()\")\n",
    "        print(f\"   2. Download Excel: fetch_excel_report('{audio_file}')\")\n",
    "        print(f\"   3. Get summary: get_report_summary('{audio_file}')\")\n",
    "        return audio_file\n",
    "    else:\n",
    "        print(f\"\\n Failed to process: {audio_file}\")\n",
    "        return None\n",
    "\n",
    "# Quick access functions (what others will use)\n",
    "def download_latest_report(save_folder=\"downloads\"):\n",
    "    \"\"\"Download the most recent Excel report\"\"\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    reports = list_all_reports()\n",
    "    if reports:\n",
    "        latest = reports[0]  # Reports are sorted by creation time desc\n",
    "        save_path = os.path.join(save_folder, latest['excel_filename'])\n",
    "        return fetch_excel_report(latest['radio_file'], save_path)\n",
    "    else:\n",
    "        print(\"No reports available\")\n",
    "        return None\n",
    "\n",
    "def download_report_by_radio_name(radio_filename, save_folder=\"downloads\"):\n",
    "    \"\"\"Download Excel report by radio filename\"\"\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    save_path = os.path.join(save_folder, f\"report_{radio_filename.replace('.mp3', '').replace('.wav', '')}.xlsx\")\n",
    "    return fetch_excel_report(radio_filename, save_path)\n",
    "\n",
    "# COMPREHENSIVE DATABASE OVERVIEW FUNCTION\n",
    "def show_database_overview():\n",
    "    \"\"\"Show complete overview of database contents\"\"\"\n",
    "    db_manager = EnhancedRadioRecordingManager()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"  COMPLETE DATABASE OVERVIEW\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get counts\n",
    "    session = db_manager.Session()\n",
    "    try:\n",
    "        ads_count = session.query(Ads).count()\n",
    "        broadcasts_count = session.query(Broadcasts).count()\n",
    "        results_count = session.query(AdDetectionResult).count()\n",
    "        reports_count = session.query(ExcelReports).count()\n",
    "        \n",
    "        print(f\" Advertisement Masters: {ads_count}\")\n",
    "        print(f\" Broadcast Recordings: {broadcasts_count}\")\n",
    "        print(f\" Detection Results: {results_count}\")\n",
    "        print(f\" Excel Reports: {reports_count}\")\n",
    "        print()\n",
    "        \n",
    "        # Show recent activity\n",
    "        recent_broadcasts = session.query(Broadcasts).order_by(Broadcasts.broadcast_date.desc()).limit(3).all()\n",
    "        if recent_broadcasts:\n",
    "            print(\" Recent Broadcasts:\")\n",
    "            for b in recent_broadcasts:\n",
    "                print(f\"   • {b.broadcast_recording} ({b.status}) - {b.broadcast_date.strftime('%Y-%m-%d')}\")\n",
    "            print()\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting overview: {e}\")\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" Enhanced Radio Advertisement Detection System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # First-time setup\n",
    "    print(\" Setting up database and populating ads table...\")\n",
    "    setup_database_tables()\n",
    "    \n",
    "    # Process the current audio clip in radio_recording folder\n",
    "    processed_file = process_current_audio_clip()\n",
    "    \n",
    "    if processed_file:\n",
    "        print(f\"\\n Available commands:\")\n",
    "        print(f\"   list_all_reports()                          # Show all reports\")\n",
    "        print(f\"   fetch_excel_report('{processed_file}')       # Download Excel\")\n",
    "        print(f\"   get_report_summary('{processed_file}')       # Show summary\")\n",
    "        print(f\"   download_latest_report()                    # Quick download\")\n",
    "        print(f\"   view_all_ads()                              # Show all ads\")\n",
    "        print(f\"   view_all_broadcasts()                       # Show all broadcasts\")\n",
    "        print(f\"   show_database_overview()                    # Complete overview\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" READY TO USE - Key Functions:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1.  setup_database_tables()                # First-time setup\")\n",
    "print(\"2.  process_current_audio_clip()           # Process current audio\")\n",
    "print(\"3.  list_all_reports()                     # Show all reports\") \n",
    "print(\"4.  fetch_excel_report('filename.mp3')     # Download specific Excel\")\n",
    "print(\"5.  get_report_summary('filename.mp3')     # Show detection summary\")\n",
    "print(\"6.  download_latest_report()               # Quick download latest\")\n",
    "print(\"7.  view_all_ads()                         # Show advertisement masters\")\n",
    "print(\"8.  view_all_broadcasts()                  # Show broadcast recordings\")\n",
    "print(\"9.  show_database_overview()               # Complete database overview\")\n",
    "print(\"10. update_ads_database()                  # Update ads from folder\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d140fef-013b-4583-b1f1-b0d0542d577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Available Reports (7):\n",
      "================================================================================\n",
      " 1. FMLogger_20211119_063901Z_98300000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_063901Z_98300000Hz_AF.xlsx\n",
      "     Ads: 9 | Created: 2025-06-11 15:57:16 | Size: 5.44 KB\n",
      "\n",
      " 2. FMLogger_20211119_085401Z_95000000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_95000000Hz_AF.xlsx\n",
      "     Ads: 31 | Created: 2025-06-11 15:42:56 | Size: 6.7 KB\n",
      "\n",
      " 3. FMLogger_20211119_085401Z_94300000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_94300000Hz_AF.xlsx\n",
      "     Ads: 12 | Created: 2025-06-11 15:32:11 | Size: 5.65 KB\n",
      "\n",
      " 4. FMLogger_20211119_085401Z_93500000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_93500000Hz_AF.xlsx\n",
      "     Ads: 31 | Created: 2025-06-11 15:20:03 | Size: 6.71 KB\n",
      "\n",
      " 5. FMLogger_20211119_085401Z_92700000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_92700000Hz_AF.xlsx\n",
      "     Ads: 26 | Created: 2025-06-11 15:07:26 | Size: 6.43 KB\n",
      "\n",
      " 6. FMLogger_20211119_085401Z_104800000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_104800000Hz_AF.xlsx\n",
      "     Ads: 8 | Created: 2025-06-11 14:53:19 | Size: 5.32 KB\n",
      "\n",
      " 7. FMLogger_20211119_085401Z_91100000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_91100000Hz_AF.xlsx\n",
      "     Ads: 24 | Created: 2025-06-11 14:46:35 | Size: 6.23 KB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 7,\n",
       "  'radio_file': 'FMLogger_20211119_063901Z_98300000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_063901Z_98300000Hz_AF.xlsx',\n",
       "  'ads_detected': 9,\n",
       "  'created': '2025-06-11 15:57:16',\n",
       "  'size_kb': 5.44,\n",
       "  'broadcast_id': 7},\n",
       " {'id': 6,\n",
       "  'radio_file': 'FMLogger_20211119_085401Z_95000000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_085401Z_95000000Hz_AF.xlsx',\n",
       "  'ads_detected': 31,\n",
       "  'created': '2025-06-11 15:42:56',\n",
       "  'size_kb': 6.7,\n",
       "  'broadcast_id': 6},\n",
       " {'id': 5,\n",
       "  'radio_file': 'FMLogger_20211119_085401Z_94300000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_085401Z_94300000Hz_AF.xlsx',\n",
       "  'ads_detected': 12,\n",
       "  'created': '2025-06-11 15:32:11',\n",
       "  'size_kb': 5.65,\n",
       "  'broadcast_id': 5},\n",
       " {'id': 4,\n",
       "  'radio_file': 'FMLogger_20211119_085401Z_93500000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_085401Z_93500000Hz_AF.xlsx',\n",
       "  'ads_detected': 31,\n",
       "  'created': '2025-06-11 15:20:03',\n",
       "  'size_kb': 6.71,\n",
       "  'broadcast_id': 4},\n",
       " {'id': 3,\n",
       "  'radio_file': 'FMLogger_20211119_085401Z_92700000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_085401Z_92700000Hz_AF.xlsx',\n",
       "  'ads_detected': 26,\n",
       "  'created': '2025-06-11 15:07:26',\n",
       "  'size_kb': 6.43,\n",
       "  'broadcast_id': 3},\n",
       " {'id': 2,\n",
       "  'radio_file': 'FMLogger_20211119_085401Z_104800000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_085401Z_104800000Hz_AF.xlsx',\n",
       "  'ads_detected': 8,\n",
       "  'created': '2025-06-11 14:53:19',\n",
       "  'size_kb': 5.32,\n",
       "  'broadcast_id': 2},\n",
       " {'id': 1,\n",
       "  'radio_file': 'FMLogger_20211119_085401Z_91100000Hz_AF.mp3',\n",
       "  'excel_filename': 'detection_results_FMLogger_20211119_085401Z_91100000Hz_AF.xlsx',\n",
       "  'ads_detected': 24,\n",
       "  'created': '2025-06-11 14:46:35',\n",
       "  'size_kb': 6.23,\n",
       "  'broadcast_id': 1}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_all_reports()                          # Show all reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "533c8d84-350a-44bf-8ae0-a0859729bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Available Reports (7):\n",
      "================================================================================\n",
      " 1. FMLogger_20211119_063901Z_98300000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_063901Z_98300000Hz_AF.xlsx\n",
      "     Ads: 9 | Created: 2025-06-11 15:57:16 | Size: 5.44 KB\n",
      "\n",
      " 2. FMLogger_20211119_085401Z_95000000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_95000000Hz_AF.xlsx\n",
      "     Ads: 31 | Created: 2025-06-11 15:42:56 | Size: 6.7 KB\n",
      "\n",
      " 3. FMLogger_20211119_085401Z_94300000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_94300000Hz_AF.xlsx\n",
      "     Ads: 12 | Created: 2025-06-11 15:32:11 | Size: 5.65 KB\n",
      "\n",
      " 4. FMLogger_20211119_085401Z_93500000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_93500000Hz_AF.xlsx\n",
      "     Ads: 31 | Created: 2025-06-11 15:20:03 | Size: 6.71 KB\n",
      "\n",
      " 5. FMLogger_20211119_085401Z_92700000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_92700000Hz_AF.xlsx\n",
      "     Ads: 26 | Created: 2025-06-11 15:07:26 | Size: 6.43 KB\n",
      "\n",
      " 6. FMLogger_20211119_085401Z_104800000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_104800000Hz_AF.xlsx\n",
      "     Ads: 8 | Created: 2025-06-11 14:53:19 | Size: 5.32 KB\n",
      "\n",
      " 7. FMLogger_20211119_085401Z_91100000Hz_AF.mp3\n",
      "     Excel: detection_results_FMLogger_20211119_085401Z_91100000Hz_AF.xlsx\n",
      "     Ads: 24 | Created: 2025-06-11 14:46:35 | Size: 6.23 KB\n",
      "\n",
      " Excel downloaded: downloads/detection_results_FMLogger_20211119_063901Z_98300000Hz_AF.xlsx\n",
      "  - Total ads detected: 9\n",
      "  - File size: 5568 bytes\n",
      "  - Created: 2025-06-11 15:57:16.138769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'downloads/detection_results_FMLogger_20211119_063901Z_98300000Hz_AF.xlsx'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_latest_report()               # Quick download latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa0708-8abc-4ab8-b694-cec5cd4be9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
